\documentclass[../Thesis.tex]{subfiles}

\begin{document}

\chapter{Introduction}

The amount of data produced has grown in the past few decades.
Nowadays data is stored in a variety of different formats and shared on the cloud.
In collaborative environments, such as the wiki web application, it is accessible at the same time from multiple devices and can be modified, often concurrently, by the users.
In these settings it is crucial to handle changes to data appropriately.
For example it is important to keep track of the history
of each object, so that at any time it is possible to roll
back to a previous version and it should strive to automatically
merge simultaneous changes as much as possible.

	\section{Description of the problem}
	\label{sec:Problem}
	In software industry specific tools called version control systems (VCS),
	such as Git \cite{GIT} and Mercurial \cite{Mercurial},
	address the problem of content management for software artifacts.
	Those tools employ line-based diff algorithms, such as GNU diff,
	that detect changes line by line and therefore are suitable 
	for source code. 
	However they are not appropriate for any kind of data, 
	because some are not naturally organized in lines of text.
	For example binary formats, such as video and images, are not
	supported and even text-based formats, such as HTML and XML, 	
	are not best handled, because single lines do not reflect 
	the underlying tree-structure of their content.
	
	Whenever revision control is needed, embedded in a specific 
	domain, these systems must be reimplemented, tailored on the specifics of 
	the formats 	involved.
	In particular the key components of these tools are a comparison function
	\texttt{diff}, which detects and collects the differences between two objects 
	in an edit script, and its inverse function \texttt{patch}, which applies 
	the edits stored in a script.	
	
	In revision control simultaneous changes need to be merged.
	Sometimes this can be achieved automatically by merging algorithms 
	such as the (recursive) \emph{three-way merge} and patch commutation 
	\cite{Darcs}, otherwise a 
	conflict is detected and the user must manually solve it and merge the 
	changes appropriately. 
	The GNU diff3 tool is a line-based algorithm employed in the
	\emph{three-way merge}, that compares three files, 
	the original version and two modified versions of that file.
	When it succeeds it creates an edit script that includes changes from 
	both the new versions and that, when applied to the original file, 
	produces a file that merges both.
	However a line-based approach restricts
	the opportunities of automatic merging for non 
	line-structured data, resulting in a greater number of conflicts and 
	ultimately additional burden to the user.

	Furthermore, even though revision systems are widely spread, their
	behaviour is understood mostly empirically.
	As a result the outcome of complex merges is often hard to predict
	and source of bug reports.

\subsection{Research Questions}
This master thesis aims to develop a prototype of a structure-aware
version control system that addresses the shortcomings of widespread 
industrial-strength version control systems, which employs 
line-based algorithms.
In particular the prototype exploits the knowledge of data formats,
in order to compute more precise diffs that take into account the structure 
of the content of files, hence improving the quality of revision control.
Specifically such a system avoids unnecessary conflicts and increases
its automatic merging capabilities. 

In order to develop such a system, the thesis addresses the following specific problems.

\paragraph{Data Format Description}
A structure-aware version control system needs to retrieve the 
actual data from each file, in order to precisely diff the content, rather
than its representation on disk, consequently each file has to parsed
 with respect to its format. Furthermore after merging the data stored in two
versions of the same file, it has to serialize it back to disk for persistency.
In this process it is essential to ensure consistency between parsing
and unparsing.

\emph{Is is possible to derive from a unique format description, both 
parser and printer for it?}

\paragraph{Generic Diff and Diff$_3$}
Considering the profusion and the complexity of data formats, it is impractical
to define specific algorithms diffing and merging algorithms for each of them.
However the data retrieved by parsers is always structured in a parse tree,
which is usually represented as a domain-specific algebraic data type.

\emph{Is it possible to exploit generic programming techniques
to implement a generic diff and merge algorithm?}

\paragraph{Formal Model}
Nowadays version control system play a vital role in collaborative environments, therefore their semantics ought to be put on a formal footing.
Their core features, management and merge of revisions, 
rely on diffing and merging algorithms, which should then be studied
closely.

\emph{Is it possible to formalize diffing and merging algorithms and study
their properties?}



\subsection{Overview}
Chapter \ref{chapter:FormatRepresentation} presents an embedded domain specific language for formats.
The EDSL allows to describe binary and text data formats, from which it 
is possible to derive automatically inverse parsers and printers.
The implementation is tested with real-world formats such as portable bit 
map images (PBM), portable grey image format (PGM) and comma separated 
values (CSV), HTML and XML.

Chapter \ref{chapter:FormalModel} presents a formal model, developed
in the Agda proof assistant \cite{Norell08, Bove09}, used to study the diff and merge algorithms.
The model is used to show that the two algorithms satisfy their specifications and to prove a number of properties.
In particular necessary and sufficient conditions for the presence of conflicts
are given.

In chapter \ref{chp:Haskell} the algorithms studied in the model are 
implemented in the Haskell programming language \cite{Marlow_haskell2010}.
Exploiting advanced type features a sizable amount of type-safety
is retained in the translation from the formal model, developed
in a language with fully-fledged dependent types, to Haskell.
The chapter includes also a proof-of-concept structure-aware version control system that employs the ideas discussed
in this thesis.

Lastly chapter \ref{chp:Conclusion} concludes, summarizing
the contributions of this thesis.


%\section{Semantics formalization}
%The same universe describing data formats will be used to reason formally about edit operations on arbitrary data, patching and diffing and lastly about \emph{branching} and \emph{merging} semantics in a structure aware context. We will be especially interested in the formal definition of branch, conflict and how they relate to the correctness of merging algorithms.

\end{document}